{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8c59d24-eb2e-4ab1-a9f2-fa1119d6a814",
   "metadata": {},
   "source": [
    "# Reinforcement learning\n",
    "RL involves an agent interacting with an environment to maximize a reward. Key components:\n",
    "\n",
    "- State (S): The agent's situation (e.g., position in the grid).\n",
    "- Action (A): Choices the agent can make (e.g., move up, down, left, right).\n",
    "- Reward (R): Feedback from the environment (e.g., +1 for reaching the goal).\n",
    "- Policy (π): The agent's strategy for choosing actions.\n",
    "- Q-Value: The expected future reward for taking an action in a state.\n",
    "\n",
    "We'll use Q-Learning, a simple RL algorithm that updates a Q-table based on rewards."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2f30e7-2e00-4ec8-b113-ab72bdddb5d3",
   "metadata": {},
   "source": [
    "## Define the Grid World Environment\n",
    "Create a 4x4 grid where the agent starts at (0,0) and aims to reach (3,3). Obstacles or walls can be added, but we’ll keep it simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ee9705d-1caa-4793-95b0-13fd24efe5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the grid size\n",
    "GRID_SIZE = 12\n",
    "\n",
    "# Initialize the Q-table (states x actions: up, down, left, right)\n",
    "q_table = np.zeros((GRID_SIZE, GRID_SIZE, 4))\n",
    "\n",
    "# Define rewards: +1 at the goal (3,3), 0 elsewhere\n",
    "rewards = np.zeros((GRID_SIZE, GRID_SIZE))\n",
    "rewards[3, 3] = 1  # Goal\n",
    "\n",
    "# Define actions\n",
    "actions = ['up', 'down', 'left', 'right']\n",
    "action_to_idx = {a: i for i, a in enumerate(actions)}\n",
    "\n",
    "# Function to take a step in the environment\n",
    "def step(state, action):\n",
    "    row, col = state\n",
    "    if action == 'up':\n",
    "        row = max(row - 1, 0)\n",
    "    elif action == 'down':\n",
    "        row = min(row + 1, GRID_SIZE - 1)\n",
    "    elif action == 'left':\n",
    "        col = max(col - 1, 0)\n",
    "    elif action == 'right':\n",
    "        col = min(col + 1, GRID_SIZE - 1)\n",
    "    \n",
    "    next_state = (row, col)\n",
    "    reward = rewards[row, col]\n",
    "    done = (row == 3 and col == 3)  # Episode ends at goal\n",
    "    return next_state, reward, done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ef8e1c-5c1b-4673-ae85-63d7fcf654a0",
   "metadata": {},
   "source": [
    "## Implement Q-Learning\n",
    "\n",
    "Q-Learning updates the Q-table using the formula:\n",
    "Q(s, a) = Q(s, a) + α [R + γ * max(Q(s', a')) - Q(s, a)]\n",
    "\n",
    "- α (alpha): Learning rate.\n",
    "- γ (gamma): Discount factor for future rewards.\n",
    "- s': Next state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7813d296-0765-414f-8ff8-e45bbed0952b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete! Q-table:\n",
      "[[[0.4964901  0.3850097  0.46644042 0.59049   ]\n",
      "  [0.55975898 0.39305442 0.51136367 0.6561    ]\n",
      "  [0.64412566 0.56412245 0.52775087 0.729     ]\n",
      "  [0.70149801 0.81       0.64767356 0.64330461]\n",
      "  [0.06157992 0.05812455 0.72897194 0.00589673]\n",
      "  [0.         0.         0.17765443 0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]]\n",
      "\n",
      " [[0.50925929 0.         0.05803545 0.04260866]\n",
      "  [0.5537552  0.         0.09844073 0.        ]\n",
      "  [0.65604929 0.04035165 0.11577024 0.081     ]\n",
      "  [0.67068864 0.9        0.55087777 0.49096334]\n",
      "  [0.65001871 0.02823675 0.1539     0.        ]\n",
      "  [0.01120534 0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]]\n",
      "\n",
      " [[0.02020336 0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.55773105 0.         0.         0.        ]\n",
      "  [0.77690623 1.         0.41050868 0.31988564]\n",
      "  [0.49977592 0.         0.09       0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.03991497 0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "alpha = 0.1  # Learning rate\n",
    "gamma = 0.9  # Discount factor\n",
    "epsilon = 0.1  # Exploration rate\n",
    "episodes = 1000\n",
    "\n",
    "# Training loop\n",
    "for episode in range(episodes):\n",
    "    state = (0, 0)  # Start at top-left\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        # Epsilon-greedy action selection\n",
    "        if np.random.random() < epsilon:\n",
    "            action = np.random.choice(actions)  # Explore\n",
    "        else:\n",
    "            action_idx = np.argmax(q_table[state[0], state[1]])  # Exploit\n",
    "            action = actions[action_idx]\n",
    "        \n",
    "        # Take a step\n",
    "        next_state, reward, done = step(state, action)\n",
    "        \n",
    "        # Update Q-table\n",
    "        action_idx = action_to_idx[action]\n",
    "        old_q = q_table[state[0], state[1], action_idx]\n",
    "        next_max_q = np.max(q_table[next_state[0], next_state[1]])\n",
    "        new_q = old_q + alpha * (reward + gamma * next_max_q - old_q)\n",
    "        q_table[state[0], state[1], action_idx] = new_q\n",
    "        \n",
    "        state = next_state\n",
    "\n",
    "print(\"Training complete! Q-table:\")\n",
    "print(q_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8284445d-f168-4b92-87c9-25f10b1f7da4",
   "metadata": {},
   "source": [
    "## Test the Learned Policy\n",
    "\n",
    "Now, let’s see the agent navigate using the trained Q-table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "592a73ff-a10e-464a-903e-6951f7da8ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned path: [(0, 0), (0, 1), (0, 2), (0, 3), (1, 3), (2, 3), (3, 3)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def test_policy():\n",
    "    state = (0, 0)\n",
    "    path = [state]\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        action_idx = np.argmax(q_table[state[0], state[1]])\n",
    "        action = actions[action_idx]\n",
    "        next_state, reward, done = step(state, action)\n",
    "        path.append(next_state)\n",
    "        state = next_state\n",
    "    \n",
    "    return path\n",
    "\n",
    "# Run and visualize\n",
    "path = test_policy()\n",
    "print(\"Learned path:\", path)\n",
    "\n",
    "# Plot the path\n",
    "grid = np.zeros((GRID_SIZE, GRID_SIZE))\n",
    "for (row, col) in path:\n",
    "    grid[row, col] = 1\n",
    "grid[3, 3] = 2  # Mark the goal\n",
    "\n",
    "plt.imshow(grid, cmap='viridis')\n",
    "plt.title(\"Agent's Path to Goal\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
