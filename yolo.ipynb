{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "5fc615f2-acb8-44b5-a58d-d83388f9041a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/brianbianchi/.pyenv/versions/3.12.9/lib/python3.12/site-packages (2.6.0)\n",
      "Requirement already satisfied: numpy in /Users/brianbianchi/.pyenv/versions/3.12.9/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: opencv-python in /Users/brianbianchi/.pyenv/versions/3.12.9/lib/python3.12/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: filelock in /Users/brianbianchi/.pyenv/versions/3.12.9/lib/python3.12/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/brianbianchi/.pyenv/versions/3.12.9/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Users/brianbianchi/.pyenv/versions/3.12.9/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/brianbianchi/.pyenv/versions/3.12.9/lib/python3.12/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /Users/brianbianchi/.pyenv/versions/3.12.9/lib/python3.12/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: setuptools in /Users/brianbianchi/.pyenv/versions/3.12.9/lib/python3.12/site-packages (from torch) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/brianbianchi/.pyenv/versions/3.12.9/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/brianbianchi/.pyenv/versions/3.12.9/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/brianbianchi/.pyenv/versions/3.12.9/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch numpy opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3d98b450-d0b7-4934-bfe6-b101e39c2749",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pafy\n",
    "import random\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6c9fb5ba-1d9d-4da1-be38-26135b706921",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "7e3d3707-21b1-4540-a815-8091711f9b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/brianbianchi/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2025-3-14 Python-3.12.9 torch-2.6.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load(\"ultralytics/yolov5\", \"yolov5s\", pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f9d3ad65-c3ea-4855-a803-3c912ecf559b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane'}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = model.names\n",
    "from itertools import islice\n",
    "dict(islice(classes.items(), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "78630833-79c8-412b-82eb-37e51cfd134a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: (159, 5, 213),\n",
       " 1: (145, 141, 123),\n",
       " 2: (215, 1, 124),\n",
       " 3: (196, 43, 251),\n",
       " 4: (146, 72, 58)}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_colors = {\n",
    "    name: (\n",
    "        random.randint(0, 255),\n",
    "        random.randint(0, 255),\n",
    "        random.randint(0, 255),\n",
    "    )\n",
    "    for name in classes\n",
    "}\n",
    "dict(islice(class_colors.items(), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "22d6ba9b-ca88-4859-9131-cc79db2d3023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_frame(frame):\n",
    "    \"\"\"\n",
    "    Takes a single frame as input, and evaluates the frame using yolo5 model.\n",
    "    :param frame: input frame in numpy/list/tuple format.\n",
    "    :return: Labels and Coordinates of objects detected by model in the frame.\n",
    "    \"\"\"\n",
    "    # model.to(device)\n",
    "    frame = [frame]\n",
    "    results = model(frame)\n",
    "    labels, cord = results.xyxyn[0][:, -1].numpy(), results.xyxyn[0][:, :-1].numpy()\n",
    "    return labels, cord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1f02feb5-181b-4b64-b667-5cb2a2ee21ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_boxes(results, frame):\n",
    "    \"\"\"\n",
    "    Takes a frame and its results as input, and plots the bounding boxes and label on to the frame.\n",
    "    :param results: contains labels and coordinates predicted by model on the given frame.\n",
    "    :param frame: Frame which has been scored.\n",
    "    :return: Frame with bounding boxes and labels ploted on it.\n",
    "    \"\"\"\n",
    "    labels, cord = results\n",
    "    n = len(labels)\n",
    "    x_shape, y_shape = frame.shape[1], frame.shape[0]\n",
    "    for i in range(n):\n",
    "        row = cord[i]\n",
    "        if row[4] >= 0.2:\n",
    "            x1, y1, x2, y2 = (\n",
    "                int(row[0] * x_shape),\n",
    "                int(row[1] * y_shape),\n",
    "                int(row[2] * x_shape),\n",
    "                int(row[3] * y_shape),\n",
    "            )\n",
    "            # bgr = (0, 255, 0)\n",
    "            bgr = class_colors[labels[i]]\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), bgr, 2)\n",
    "            cv2.putText(\n",
    "                frame,\n",
    "                classes[int(labels[i])],\n",
    "                (x1, y1),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.9,\n",
    "                bgr,\n",
    "                2,\n",
    "            )\n",
    "\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85add21a-9c52-486f-8da7-2cfb7bd48033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download a mp4 video\n",
    "# tool: https://cobalt.tools/\n",
    "# example: https://www.youtube.com/watch?v=PwUEo7zEtzg\n",
    "# torch.set_warn_always(False)\n",
    "\n",
    "player = cv2.VideoCapture(\"in.mp4\")\n",
    "assert player.isOpened()\n",
    "x_shape = int(player.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "y_shape = int(player.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "out = cv2.VideoWriter(\"out.mp4\", cv2.VideoWriter_fourcc(*'mp4v'), 20, (x_shape, y_shape))\n",
    "while True:\n",
    "    ret, frame = player.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    results = eval_frame(frame)\n",
    "    frame = plot_boxes(results, frame)\n",
    "    out.write(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b3d9f2c2-957d-44cb-9864-58988bcf25ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"in.mp4\" controls  width=\"700\" >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipd.Video('in.mp4', width=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d4895a22-0ed9-405e-8a71-c422e8760702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"out.mp4\" controls  width=\"700\" >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipd.Video('out.mp4', width=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcb554e-f8a4-46de-9fe1-9dacbfb38b68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
